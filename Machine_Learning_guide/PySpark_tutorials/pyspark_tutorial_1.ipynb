{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"line-height:0.4\">\n",
    "<h1 style=\"color:#0FCBC6\"> PySpark 1: Basic notions </h1>\n",
    "<span style=\"display: inline-block;\">\n",
    "    <h3 style=\"color: lightblue; display: inline;\">Keywords:</h3> Dataframe operations + Files + RDD\n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import isnan, col, when, rand\n",
    "from pyspark.ml.feature import Imputer\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `SparkSession` with the `SparkSession.builder`\n",
    "=> Set various configuration options and attributes to customize its behavior.\n",
    "\n",
    "1. **`appName`:** Specifies the name of your Spark application. This name will appear in the Spark UI and logs.\n",
    "\n",
    "2. **`master`:** Specifies the cluster manager or cluster URL to connect to. You can set this to \"local\" for local testing, \"yarn\" for YARN cluster, or a specific URL for other cluster managers.\n",
    "\n",
    "3. **`config`:** Sets additional configuration options using a dictionary.\n",
    "\n",
    "4. **`config(\"spark.some.option\")` :** Sets specific Spark configuration options using the `config` method.      \n",
    "&emsp;&emsp;=> `config(\"spark.executor.memory\", \"2g\")` Sets the amount of memory per executor.\n",
    "\n",
    "5. **`enableHiveSupport`:** Enables access to \"Hive features\".\n",
    "\n",
    "6. **`getOrCreate()`:** Retrieves an existing `SparkSession` or creates a new one if it doesn't exist.\n",
    "\n",
    "7. **Others:** \n",
    "   - `spark.executor.cores`: The number of cores to use on each executor.\n",
    "   - `spark.driver.memory`: The amount of memory to allocate to the driver.\n",
    "   - `spark.sql.shuffle.partitions`: The number of partitions to use when shuffling data in Spark SQL operations.\n",
    "   - `spark.default.parallelism`: The default level of parallelism to use for RDDs and DataFrames.\n",
    "   - `spark.serializer`: The serializer used for serializing data. (Default: org.apache.spark.serializer.JavaSerializer)\n",
    "   - `spark.logConf`: Controls whether Spark configuration is logged when the `SparkSession` is created."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#0FCBC6\"><u>Example 1</u></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/15 18:02:38 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# Create a Spark session with custom configurations\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CustomSparkSession\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.cores\", \"4\") \\\n",
    "    .config(\"spark.default.parallelism\", \"8\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"10\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" N.B. Stop the Spark session when you're done! \n",
    "The spark.stop() method gracefully shuts down the Spark session, releases resources, and terminates any running Spark jobs. \n",
    "To prevent resource leakage especially when working in an interactive environment like Jupyter Notebook.\n",
    "\"\"\"\n",
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/15 17:46:03 WARN Utils: Your hostname, hpmint resolves to a loopback address: 127.0.1.1; using 192.168.1.81 instead (on interface eno1)\n",
      "23/08/15 17:46:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/15 17:46:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PySparkTutorial\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from a CSV file\n",
    "data_path = \"./datasets_for_pyspark/naggfs.csv\"\n",
    "df = spark.read.csv(data_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+-----+--------------------+\n",
      "|                 du1|                 du2|    id|label|             message|\n",
      "+--------------------+--------------------+------+-----+--------------------+\n",
      "| i honeslty never...| i would make it ...|2_2374|    N| < i honeslty nev...|\n",
      "| i honeslty never...|                 18 |2_2375|    N| < i honeslty nev...|\n",
      "| i honeslty never...|    but here i am , |2_2376|    D| < i honeslty nev...|\n",
      "| i would make it ...|                 18 |2_2377|    N|i honeslty never ...|\n",
      "| i would make it ...|    but here i am , |2_2378|    D|i honeslty never ...|\n",
      "| i would make it ...| living it up on ...|2_2379|    C|i honeslty never ...|\n",
      "|                 18 |    but here i am , |2_2380|    N|i honeslty never ...|\n",
      "|                 18 | living it up on ...|2_2381|    N|i honeslty never ...|\n",
      "|                 18 |           2020ðŸ‘ŒðŸ¼ |2_2382|    N|i honeslty never ...|\n",
      "|    but here i am , | living it up on ...|2_2383|    C|i honeslty never ...|\n",
      "|    but here i am , |           2020ðŸ‘ŒðŸ¼ |2_2384|    C|i honeslty never ...|\n",
      "|    but here i am , | i really need th...|2_2385|    N|i honeslty never ...|\n",
      "|    but here i am , | because i canâ€™t ...|2_2386|    D|i honeslty never ...|\n",
      "| living it up on ...|           2020ðŸ‘ŒðŸ¼ |2_2387|    N|i honeslty never ...|\n",
      "| living it up on ...| i really need th...|2_2388|    D|i honeslty never ...|\n",
      "| living it up on ...| because i canâ€™t ...|2_2389|    D|i honeslty never ...|\n",
      "| living it up on ...|               ðŸ¤žðŸ¼ |2_2390|    D|i honeslty never ...|\n",
      "|           2020ðŸ‘ŒðŸ¼ | i really need th...|2_2391|    N|i honeslty never ...|\n",
      "|           2020ðŸ‘ŒðŸ¼ | because i canâ€™t ...|2_2392|    N|i honeslty never ...|\n",
      "|           2020ðŸ‘ŒðŸ¼ |               ðŸ¤žðŸ¼ |2_2393|    N|i honeslty never ...|\n",
      "+--------------------+--------------------+------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Load data from JSON \"\"\"\n",
    "# Read \n",
    "json_path = \"./datasets_for_pyspark/for_tutorial_1/train_small.json\"\n",
    "\"\"\"\n",
    "# To create the Dataframe\n",
    "# => using df = spark.read.json(json_path) is not enough \n",
    "# Add 'multiline' option avoid the error:  Since Spark 2.3, the queries from raw JSON/CSV files are disallowed when the referenced columns only include the internal corrupt record column\n",
    "\"\"\"\n",
    "# Dataframe\n",
    "df_j = spark.read.option(\"multiline\", \"true\").option(\"mode\", \"PERMISSIVE\").json(json_path)\n",
    "df_j.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing Data\n",
    "output_path = \"./datasets_for_pyspark/output_created_can_be_cancelled.csv\"\n",
    "df.write.csv(output_path, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[du1: string, du2: string, id: string, label: string, message: string]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_j"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#0FCBC6\"> => Display DataFrame and Schema </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+----------+-----------+-------+--------+--------------------+--------------------+--------------------+--------------+--------------+--------------+--------------+\n",
      "|Series_reference| Period|Data_value|     STATUS|  UNITS|MAGNTUDE|             Subject|               Group|      Series_title_1|Series_title_2|Series_title_3|Series_title_4|Series_title_5|\n",
      "+----------------+-------+----------+-----------+-------+--------+--------------------+--------------------+--------------------+--------------+--------------+--------------+--------------+\n",
      "|GFSA.SGS01G01Z90|2009.06|      3881|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2010.06|     -3356|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2011.06|    -13181|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2012.06|     -3417|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2013.06|      -461|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2014.06|      1530|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2015.06|      4734|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2016.06|      5710|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2017.06|      8021|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2018.06|      9419|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2019.06|      9871|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2020.06|    -13854|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2021.06|      -904|PROVISIONAL|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z91|2009.06|        40|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net lending/borro...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z91|2010.06|     -6986|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net lending/borro...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z91|2011.06|    -15300|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net lending/borro...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z91|2012.06|     -5678|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net lending/borro...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z91|2013.06|     -3921|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net lending/borro...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z91|2014.06|     -2173|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net lending/borro...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z91|2015.06|       338|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net lending/borro...|          null|          null|          null|          null|\n",
      "+----------------+-------+----------+-----------+-------+--------+--------------------+--------------------+--------------------+--------------+--------------+--------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Series_reference: string (nullable = true)\n",
      " |-- Period: double (nullable = true)\n",
      " |-- Data_value: integer (nullable = true)\n",
      " |-- STATUS: string (nullable = true)\n",
      " |-- UNITS: string (nullable = true)\n",
      " |-- MAGNTUDE: integer (nullable = true)\n",
      " |-- Subject: string (nullable = true)\n",
      " |-- Group: string (nullable = true)\n",
      " |-- Series_title_1: string (nullable = true)\n",
      " |-- Series_title_2: string (nullable = true)\n",
      " |-- Series_title_3: string (nullable = true)\n",
      " |-- Series_title_4: string (nullable = true)\n",
      " |-- Series_title_5: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#0FCBC6\"> => Columns and Rows </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[STATUS: string]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"STATUS\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#0FCBC6\"> => Grouping and Aggregation </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[MAGNTUDE: int, avg(MAGNTUDE): double]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(\"MAGNTUDE\").agg({\"MAGNTUDE\": \"avg\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#0FCBC6\"> => Transformations </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Series_reference: string, Period: double, Data_value: int, STATUS: string, UNITS: string, MAGNTUDE: int, Subject: string, Group: string, Series_title_1: string, Series_title_2: string, Series_title_3: string, Series_title_4: string, Series_title_5: string, new_column: int]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\" Add Columns \"\"\"\n",
    "df.withColumn(\"new_column\", df[\"MAGNTUDE\"] + 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Series_reference: string, Period: double, Data_value: int, STATUS: string, UNITS: string, MAGNTUDE: int, Subject: string, Group: string, Series_title_1: string, Series_title_2: string, Series_title_3: string, Series_title_4: string, Series_title_5: string]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Rename Columns \"\"\"\n",
    "df.withColumnRenamed(\"new_column\", \"MAGNITUDE_ADDED_LATER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Series_reference: string, Period: double, Data_value: int, STATUS: string, UNITS: string, MAGNTUDE: int, Subject: string, Group: string, Series_title_1: string, Series_title_2: string, Series_title_3: string, Series_title_4: string, Series_title_5: string]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Drop Columns \"\"\"\n",
    "df.drop(\"MAGNITUDE_ADDED_LATER\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#0FCBC6\"> => SQL Queries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"table_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[Series_reference: string, Period: double, Data_value: int, STATUS: string, UNITS: string, MAGNTUDE: int, Subject: string, Group: string, Series_title_1: string, Series_title_2: string, Series_title_3: string, Series_title_4: string, Series_title_5: string]\n",
      "\n",
      "+----------------+-------+----------+-------+-------+--------+--------------------+--------------------+--------------------+--------------+--------------+--------------+--------------+\n",
      "|Series_reference| Period|Data_value| STATUS|  UNITS|MAGNTUDE|             Subject|               Group|      Series_title_1|Series_title_2|Series_title_3|Series_title_4|Series_title_5|\n",
      "+----------------+-------+----------+-------+-------+--------+--------------------+--------------------+--------------------+--------------+--------------+--------------+--------------+\n",
      "|GFSA.SGS01G01Z90|2009.06|      3881|REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2015.06|      4734|REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2016.06|      5710|REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2017.06|      8021|REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2018.06|      9419|REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2019.06|      9871|REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z91|2017.06|      3702|REVISED|Dollars|       6|Government Financ...|General Governmen...|Net lending/borro...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z91|2018.06|      3882|REVISED|Dollars|       6|Government Financ...|General Governmen...|Net lending/borro...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z91|2019.06|      3694|REVISED|Dollars|       6|Government Financ...|General Governmen...|Net lending/borro...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G02121|2009.06|      2278|  FINAL|Dollars|       6|Government Financ...|General Governmen...|Social security c...|          null|          null|          null|          null|\n",
      "+----------------+-------+----------+-------+-------+--------+--------------------+--------------------+--------------------+--------------+--------------+--------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df = spark.sql(\"SELECT * FROM table_name WHERE Data_value > 2000\")\n",
    "print(result_df)\n",
    "print()\n",
    "result_df.show(n=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#0FCBC6\"> => Handling Missing Data </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+----------+-----------+-------+--------+--------------------+--------------------+--------------------+--------------+--------------+--------------+--------------+\n",
      "|Series_reference| Period|Data_value|     STATUS|  UNITS|MAGNTUDE|             Subject|               Group|      Series_title_1|Series_title_2|Series_title_3|Series_title_4|Series_title_5|\n",
      "+----------------+-------+----------+-----------+-------+--------+--------------------+--------------------+--------------------+--------------+--------------+--------------+--------------+\n",
      "|GFSA.SGS01G01Z90|2009.06|      3881|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2010.06|     -3356|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2011.06|    -13181|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2012.06|     -3417|    REVISED|   null|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2013.06|      -461|    REVISED|   null|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2014.06|      1530|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2015.06|      4734|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2016.06|      5710|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2017.06|      8021|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2018.06|      9419|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2019.06|      9871|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2020.06|    -13854|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z90|2021.06|      -904|PROVISIONAL|   null|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z91|2009.06|        40|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net lending/borro...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z91|2010.06|     -6986|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net lending/borro...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z91|2011.06|    -15300|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net lending/borro...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z91|2012.06|     -5678|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net lending/borro...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z91|2013.06|     -3921|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net lending/borro...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z91|2014.06|     -2173|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net lending/borro...|          null|          null|          null|          null|\n",
      "|GFSA.SGS01G01Z91|2015.06|       338|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net lending/borro...|          null|          null|          null|          null|\n",
      "+----------------+-------+----------+-----------+-------+--------+--------------------+--------------------+--------------------+--------------+--------------+--------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Insert NaN values randomly \"\"\"\n",
    "\n",
    "# Specify the probability of NaN insertion\n",
    "nan_probability = 0.2\n",
    "df_with_nan = df.withColumn(\"UNITS\", when(rand() < nan_probability, None).otherwise(col(\"UNITS\")))\n",
    "df_with_nan.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaN values: []\n"
     ]
    }
   ],
   "source": [
    "# Search for NaN values\n",
    "nan_columns = [col_name for col_name in df_with_nan.columns if df.select(isnan(col(col_name))).collect()[0][0]]\n",
    "print(\"Columns with NaN values:\", nan_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaN values: ['Series_title_2', 'Series_title_3', 'Series_title_4', 'Series_title_5']\n"
     ]
    }
   ],
   "source": [
    "# Identify columns with Null values\n",
    "nan_columns = [col_name for col_name in df_with_nan.columns if df.filter(col(col_name).isNull()).count() > 0]\n",
    "print(\"Columns with NaN values:\", nan_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Options: \\ndf.dropna()\\ndf.fillna(0)\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Options: \n",
    "df.dropna()\n",
    "df.fillna(0)\n",
    "\"\"\"\n",
    "#df.dropna()\n",
    "#df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Imputer for numbers \"\"\"\n",
    "# N.B. => IllegalArgumentException: requirement failed: Column Series_title_2 must be of type numeric but was actually of type string.\n",
    "# imputer = Imputer(inputCols=[\"Series_title_2\"], outputCols=[\"Series_title_4\"])\n",
    "# df_imputed = imputer.fit(df_with_nan).transform(df_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+----------+-----------+-------+--------+--------------------+--------------------+--------------------+--------------+--------------+--------------+--------------+\n",
      "|Series_reference| Period|Data_value|     STATUS|  UNITS|MAGNTUDE|             Subject|               Group|      Series_title_1|Series_title_2|Series_title_3|Series_title_4|Series_title_5|\n",
      "+----------------+-------+----------+-----------+-------+--------+--------------------+--------------------+--------------------+--------------+--------------+--------------+--------------+\n",
      "|GFSA.SGS01G01Z90|2009.06|      3881|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null| default_value|          null|\n",
      "|GFSA.SGS01G01Z90|2010.06|     -3356|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null| default_value|          null|\n",
      "|GFSA.SGS01G01Z90|2011.06|    -13181|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null| default_value|          null|\n",
      "|GFSA.SGS01G01Z90|2012.06|     -3417|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null| default_value|          null|\n",
      "|GFSA.SGS01G01Z90|2013.06|      -461|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null| default_value|          null|\n",
      "|GFSA.SGS01G01Z90|2014.06|      1530|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null| default_value|          null|\n",
      "|GFSA.SGS01G01Z90|2015.06|      4734|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null| default_value|          null|\n",
      "|GFSA.SGS01G01Z90|2016.06|      5710|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null| default_value|          null|\n",
      "|GFSA.SGS01G01Z90|2017.06|      8021|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null| default_value|          null|\n",
      "|GFSA.SGS01G01Z90|2018.06|      9419|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null| default_value|          null|\n",
      "|GFSA.SGS01G01Z90|2019.06|      9871|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null| default_value|          null|\n",
      "|GFSA.SGS01G01Z90|2020.06|    -13854|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null| default_value|          null|\n",
      "|GFSA.SGS01G01Z90|2021.06|      -904|PROVISIONAL|Dollars|       6|Government Financ...|General Governmen...|Net operating bal...|          null|          null| default_value|          null|\n",
      "|GFSA.SGS01G01Z91|2009.06|        40|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net lending/borro...|          null|          null| default_value|          null|\n",
      "|GFSA.SGS01G01Z91|2010.06|     -6986|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net lending/borro...|          null|          null| default_value|          null|\n",
      "|GFSA.SGS01G01Z91|2011.06|    -15300|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net lending/borro...|          null|          null| default_value|          null|\n",
      "|GFSA.SGS01G01Z91|2012.06|     -5678|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net lending/borro...|          null|          null| default_value|          null|\n",
      "|GFSA.SGS01G01Z91|2013.06|     -3921|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net lending/borro...|          null|          null| default_value|          null|\n",
      "|GFSA.SGS01G01Z91|2014.06|     -2173|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net lending/borro...|          null|          null| default_value|          null|\n",
      "|GFSA.SGS01G01Z91|2015.06|       338|    REVISED|Dollars|       6|Government Financ...|General Governmen...|Net lending/borro...|          null|          null| default_value|          null|\n",
      "+----------------+-------+----------+-----------+-------+--------+--------------------+--------------------+--------------------+--------------+--------------+--------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Imputer for strings \"\"\"\n",
    "column_to_impute = \"Series_title_4\"\n",
    "default_value = \"default_value\"\n",
    "imputed_df = df.withColumn(column_to_impute, when(col(column_to_impute).isNull(), default_value).otherwise(col(column_to_impute)))\n",
    "imputed_df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#0FCBC6\"> => Create dataframes </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|col1|col2|col3|\n",
      "+----+----+----+\n",
      "|   1|   A|10.5|\n",
      "|   2|   B|20.0|\n",
      "|   3|   C|15.3|\n",
      "|   4|   D| 8.7|\n",
      "|   5|   E|12.2|\n",
      "|   6|   F|18.9|\n",
      "|   7|   G|25.1|\n",
      "|   8|   H| 9.4|\n",
      "|   9|   I|14.7|\n",
      "|  10|   J|22.3|\n",
      "+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a list of raw objects\n",
    "data = [\n",
    "    Row(col1=1, col2=\"A\", col3=10.5),\n",
    "    Row(col1=2, col2=\"B\", col3=20.0),\n",
    "    Row(col1=3, col2=\"C\", col3=15.3),\n",
    "    Row(col1=4, col2=\"D\", col3=8.7),\n",
    "    Row(col1=5, col2=\"E\", col3=12.2),\n",
    "    Row(col1=6, col2=\"F\", col3=18.9),\n",
    "    Row(col1=7, col2=\"G\", col3=25.1),\n",
    "    Row(col1=8, col2=\"H\", col3=9.4),\n",
    "    Row(col1=9, col2=\"I\", col3=14.7),\n",
    "    Row(col1=10, col2=\"J\", col3=22.3)\n",
    "]\n",
    "\n",
    "# DataFrame from list \n",
    "df = spark.createDataFrame(data)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#0FCBC6\"><u>Example 2</u></h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#0FCBC6\"> => Files </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pride and Prejudice:\n",
      "['It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.']\n",
      "\n",
      "\n",
      "Moby-Dick:\n",
      "['Call me Ishmael. Some years ago - never mind how long precisely - having little or no money in my purse, and nothing particular to interest me on shore...', '']\n",
      "\n",
      "\n",
      "Alice's Adventures in Wonderland:\n",
      "['Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do. Once or twice she had peeped into the book her sister was reading...', '']\n"
     ]
    }
   ],
   "source": [
    "# Stop the SparkSession before creating the SparkContext \n",
    "spark.stop()\n",
    "# Stop the current session, to run again this cell\n",
    "sc.stop()\n",
    "\n",
    "# Create SparkContext object \n",
    "sc = SparkContext(appName=\"FileHandling\")\n",
    "\n",
    "# Read a text file\n",
    "pride_rdd = sc.textFile(\"./datasets_for_pyspark/text_files/pride_and_prejudice.txt\")\n",
    "moby_dick_rdd = sc.textFile(\"./datasets_for_pyspark/text_files/moby_dick.txt\")\n",
    "alice_rdd = sc.textFile(\"./datasets_for_pyspark/text_files/alice.txt\")\n",
    "\n",
    "\n",
    "# Show the content of RDDs\n",
    "print(\"Pride and Prejudice:\")\n",
    "print(pride_rdd.collect())\n",
    "print()\n",
    "print(\"\\nMoby-Dick:\")\n",
    "print(moby_dick_rdd.collect())\n",
    "print()\n",
    "print(\"\\nAlice's Adventures in Wonderland:\")\n",
    "print(alice_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('file:/home/notto4/Desktop/coding_trials_drafts/AI_ML_DL/PySpark_tutorials/datasets_for_pyspark/text_files/pride_and_prejudice.txt',\n",
       "  'It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\\n'),\n",
       " ('file:/home/notto4/Desktop/coding_trials_drafts/AI_ML_DL/PySpark_tutorials/datasets_for_pyspark/text_files/moby_dick.txt',\n",
       "  'Call me Ishmael. Some years ago - never mind how long precisely - having little or no money in my purse, and nothing particular to interest me on shore...\\n\\n'),\n",
       " ('file:/home/notto4/Desktop/coding_trials_drafts/AI_ML_DL/PySpark_tutorials/datasets_for_pyspark/text_files/alice.txt',\n",
       "  'Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do. Once or twice she had peeped into the book her sister was reading...\\n\\n')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read multiple text files as key-value pairs\n",
    "kv_rdd = sc.wholeTextFiles(\"./datasets_for_pyspark/text_files\")\n",
    "kv_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of lines:\n",
      "Pride and Prejudice: 1\n",
      "Moby-Dick: 2\n",
      "Alice's Adventures in Wonderland: 2\n"
     ]
    }
   ],
   "source": [
    "# Count the number of lines in each RDD\n",
    "pride_lines = pride_rdd.count()\n",
    "moby_dick_lines = moby_dick_rdd.count()\n",
    "alice_lines = alice_rdd.count()\n",
    "\n",
    "print(\"\\nNumber of lines:\")\n",
    "print(\"Pride and Prejudice:\", pride_lines)\n",
    "print(\"Moby-Dick:\", moby_dick_lines)\n",
    "print(\"Alice's Adventures in Wonderland:\", alice_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Longest Lines:\n",
      "Pride and Prejudice: It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\n",
      "Moby-Dick: Call me Ishmael. Some years ago - never mind how long precisely - having little or no money in my purse, and nothing particular to interest me on shore...\n",
      "Alice's Adventures in Wonderland: Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do. Once or twice she had peeped into the book her sister was reading...\n"
     ]
    }
   ],
   "source": [
    "# Actions: Find the longest line in each RDD\n",
    "longest_line_pride = pride_rdd.max(key=lambda line: len(line))\n",
    "longest_line_moby_dick = moby_dick_rdd.max(key=lambda line: len(line))\n",
    "longest_line_alice = alice_rdd.max(key=lambda line: len(line))\n",
    "\n",
    "print(\"\\nLongest Lines:\")\n",
    "print(\"Pride and Prejudice:\", longest_line_pride)\n",
    "print(\"Moby-Dick:\", longest_line_moby_dick)\n",
    "print(\"Alice's Adventures in Wonderland:\", longest_line_alice)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#0FCBC6\"> => Recap on RDD </h3>    \n",
    "<div style=\"margin-top: -15px;\">\n",
    "\n",
    "A Resilient Distributed Dataset (RDD), is the fundamental data structure in Spark (the basic abstraction).      \n",
    "RDDs represent an immutable, partitioned collection of elements (data) that can be processed in parallel across a cluster of computers.    \n",
    "RDDs provide an abstraction layer that allows you to perform transformations and actions on distributed data without worrying <br> about the low-level details of parallel processing and fault recovery.\n",
    "\n",
    "2 types of operations:\n",
    "<div style=\"margin-top: -15px;\">\n",
    "\n",
    "- Transformations: These are operations that create a new RDD from an existing one. <br> \n",
    "Transformations are performed lazily and build up a sequence of transformations in the lineage.\n",
    "- Actions: These are operations that return a value to the driver program or write data to an external storage system.          \n",
    "Actions trigger the actual execution of the transformations and bring data from distributed nodes back to the driver program.           \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Numbers: [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
      "Total: 110\n",
      "Accumulator Value: 110\n"
     ]
    }
   ],
   "source": [
    "def process_number(number):\n",
    "    \"\"\" Perform an action using the RDD and accumulator. \"\"\"\n",
    "    global accumulator\n",
    "    accumulator += number\n",
    "    return number * 2\n",
    "\n",
    "try:\n",
    "    # Create an RDD from a list of numbers\n",
    "    numbers_rdd = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "    print(\"Number of partitions:\", numbers_rdd.getNumPartitions())\n",
    "\n",
    "    # Create a broadcast variable\n",
    "    broadcast_var = sc.broadcast({\"key\": \"value\"})\n",
    "    # Create an accumulator\n",
    "    accumulator = sc.accumulator(0)\n",
    "\n",
    "    processed_numbers_rdd = numbers_rdd.map(process_number)\n",
    "    total = processed_numbers_rdd.sum()\n",
    "\n",
    "    print(\"Processed Numbers:\", processed_numbers_rdd.collect())\n",
    "    print(\"Total:\", total)\n",
    "    print(\"Accumulator Value:\", accumulator.value)\n",
    "\n",
    "finally:\n",
    "    # Stop the Spark context\n",
    "    sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
