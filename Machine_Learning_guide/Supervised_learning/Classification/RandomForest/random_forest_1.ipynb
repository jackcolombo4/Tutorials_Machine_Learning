{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be033982",
   "metadata": {},
   "source": [
    "<div style=\"line-height:1.2;\">\n",
    "\n",
    "<h1 style=\"color:#0FA345; margin-bottom: 0.2em;\">Random Forest Classification 1</h1>\n",
    "<h4 style=\"margin-top: 0.2em; margin-bottom: 0.5em;\"> Example with sklearn RandomForestClassifier on the iris dataset. Focus on metrics. </h4>\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"line-height:1.4; margin-top: 0.2em;\">\n",
    "<span>\n",
    "    <h3 style=\"color: lightblue; display: inline; margin-right: 0.5em;\">Keywords:</h3>\n",
    "    sklearn ignore_warnings + RandomizedSearchCV + classification_report + Tensorboard with PyTorch + jaccard_score + hamming loss\n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52f2f0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, since already installed\n"
     ]
    }
   ],
   "source": [
    "%%script echo Skipping, since already installed\n",
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61cc78fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorboardX import SummaryWriter \n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, validation_curve, StratifiedKFold, ShuffleSplit, cross_val_score\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, hamming_loss, classification_report\n",
    "\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics import precision_recall_fscore_support as scorep\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "\n",
    "from yellowbrick.model_selection import ValidationCurve\n",
    "\n",
    "try:\n",
    "    from sklearn.utils._testing import ignore_warnings\n",
    "except ImportError:\n",
    "    from sklearn.utils.testing import ignore_warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce5886cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = \"./data/iris_correct.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "439a135f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal.length  sepal.width  petal.length  petal.width    variety\n",
       "0             5.1          3.5           1.4          0.2     Setosa\n",
       "1             4.9          3.0           1.4          0.2     Setosa\n",
       "2             4.7          3.2           1.3          0.2     Setosa\n",
       "3             4.6          3.1           1.5          0.2     Setosa\n",
       "4             5.0          3.6           1.4          0.2     Setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  Virginica\n",
       "146           6.3          2.5           5.0          1.9  Virginica\n",
       "147           6.5          3.0           5.2          2.0  Virginica\n",
       "148           6.2          3.4           5.4          2.3  Virginica\n",
       "149           5.9          3.0           5.1          1.8  Virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset = pd.read_csv(location, skiprows=None, engine='python')\n",
    "my_dataset.drop(columns=['species'], inplace=True)\n",
    "my_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c2e0f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping: The dataset it is already in its correct form.\n"
     ]
    }
   ],
   "source": [
    "%%script echo Skipping: The dataset it is already in its correct form.\n",
    "my_dataset[\"sepal_width\"] = [float(str(i).replace(\",\", \"\")) for i in my_dataset[\"sepal_width\"]]\n",
    "my_dataset[\"petal_length\"] = [float(str(i).replace(\",\", \"\")) for i in my_dataset[\"petal_length\"]]\n",
    "my_dataset[\"sepal_length\"] = [float(str(i).replace(\",\", \"\")) for i in my_dataset[\"sepal_length\"]]\n",
    "my_dataset[\"petal_width\"] = [float(str(i).replace(\",\", \"\")) for i in my_dataset[\"petal_width\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae2ac8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = shuffle(my_dataset, random_state=3)\n",
    "if 'variety' in my_dataset.columns:\n",
    "    Y = my_dataset[['variety']]\n",
    "    X = my_dataset\n",
    "    X.pop('variety')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54a418b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    sepal.length  sepal.width  petal.length  petal.width\n",
       " 47           4.6          3.2           1.4          0.2\n",
       " 3            4.6          3.1           1.5          0.2\n",
       " 31           5.4          3.4           1.5          0.4\n",
       " 25           5.0          3.0           1.6          0.2\n",
       " 15           5.7          4.4           1.5          0.4,\n",
       " (150, 4))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(), X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb0a5783",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Split:\n",
    "Train set correspond to the 75% of the original dataset\n",
    "Test set is 10% of the initial dataset\n",
    "Validation set is now 15% of the initial data set\n",
    "\"\"\"\n",
    "train_ratio = 0.80\n",
    "validation_ratio = 0.10\n",
    "test_ratio = 0.10\n",
    "X_train, X_test, Y_train, Y_test = tts(X, Y, test_size=1 - train_ratio)\n",
    "\n",
    "X_val, X_test, Y_val, Y_test = tts(X_test, Y_test, test_size=test_ratio/(test_ratio + validation_ratio)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30b9fd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        variety\n",
      "132   Virginica\n",
      "147   Virginica\n",
      "62   Versicolor\n",
      "143   Virginica\n",
      "71   Versicolor\n",
      "..          ...\n",
      "122   Virginica\n",
      "139   Virginica\n",
      "134   Virginica\n",
      "26       Setosa\n",
      "44       Setosa\n",
      "\n",
      "[120 rows x 1 columns]         variety\n",
      "75   Versicolor\n",
      "30       Setosa\n",
      "77   Versicolor\n",
      "20       Setosa\n",
      "96   Versicolor\n",
      "14       Setosa\n",
      "27       Setosa\n",
      "69   Versicolor\n",
      "1        Setosa\n",
      "149   Virginica\n",
      "141   Virginica\n",
      "97   Versicolor\n",
      "84   Versicolor\n",
      "87   Versicolor\n",
      "92   Versicolor         variety\n",
      "79   Versicolor\n",
      "58   Versicolor\n",
      "135   Virginica\n",
      "83   Versicolor\n",
      "148   Virginica\n",
      "103   Virginica\n",
      "42       Setosa\n",
      "23       Setosa\n",
      "19       Setosa\n",
      "43       Setosa\n",
      "126   Virginica\n",
      "54   Versicolor\n",
      "95   Versicolor\n",
      "145   Virginica\n",
      "119   Virginica\n"
     ]
    }
   ],
   "source": [
    "print(Y_train, Y_val, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cfbfc5",
   "metadata": {},
   "source": [
    "#### => RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fafeb36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to overtime\n"
     ]
    }
   ],
   "source": [
    "%%script echo Skipping due to overtime \n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "                'max_features': max_features,\n",
    "                'max_depth': max_depth,\n",
    "                'min_samples_split': min_samples_split,\n",
    "                'min_samples_leaf': min_samples_leaf,\n",
    "                'bootstrap': bootstrap}\n",
    "\n",
    "####### Search for best hyperparameters with the random grid, using 3 fold cross-validation.\n",
    "# Create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, \n",
    "                                verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the search model\n",
    "rf_random.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d4df2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, since the RandomizedSearchCV was not completed.\n"
     ]
    }
   ],
   "source": [
    "%%script echo Skipping, since the RandomizedSearchCV was not completed.\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43cb1504",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=1000, min_samples_split = 5,\n",
    "                            min_samples_leaf=1, \n",
    "                            max_features='sqrt',\n",
    "                            max_depth=30,class_weight=\"balanced\",bootstrap = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28176dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120,), (120, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change shape of targets' vector to test  \n",
    "Y_train2 = np.ravel(Y_train)\n",
    "Y_train2.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6379ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, np.ravel(Y_train)); #use the flattened array!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d43a5d",
   "metadata": {},
   "source": [
    "### => Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99ea133f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/notto4/anaconda3/envs/MLearning/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/notto4/anaconda3/envs/MLearning/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:\n",
      "0.9916666666666667\n",
      "SCORE test:\n",
      "0.8666666666666667\n",
      "CROSSSCORE val:\n",
      "[0.66666667 1.         1.         0.66666667 1.        ]\n",
      "0.87 accuracy with a standard deviation of 0.16\n",
      "CROSSSCORE tra:\n",
      "[0.95833333 0.91666667 0.95833333 0.95833333 1.        ]\n",
      "0.96 accuracy with a standard deviation of 0.03\n",
      "CROSSSCORE test:\n",
      "[1.         1.         0.66666667 1.         0.66666667]\n",
      "0.87 accuracy with a standard deviation of 0.16\n",
      "How many coumns ins my_dataset? 4\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Cross validation.\n",
    "Reshape target variables to 1D arrays with ravel()\n",
    "=> To avoid the error : DataConversionWarning: A column-vector y was passed when a 1d array was expected. \n",
    "\"\"\"\n",
    "Y_train = np.ravel(Y_train)\n",
    "Y_test = np.ravel(Y_test)\n",
    "Y_val = np.ravel(Y_val)\n",
    "\n",
    "scores = clf.score(X_train, Y_train)\n",
    "scores_test = clf.score(X_test, Y_test)\n",
    "cross_scores_tra = cross_val_score(clf, X_train, Y_train, cv=5) \n",
    "cross_scores_val = cross_val_score(clf, X_val, Y_val, cv=5)\n",
    "cross_scores_test = cross_val_score(clf, X_test, Y_test, cv=5)\n",
    "\n",
    "print(\"SCORE:\")\n",
    "print(scores)\n",
    "print(\"SCORE test:\")\n",
    "print(scores_test)\n",
    "\n",
    "print(\"CROSSSCORE val:\")\n",
    "print(cross_scores_val)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (cross_scores_val.mean(), cross_scores_val.std()))\n",
    "print(\"CROSSSCORE tra:\")\n",
    "print(cross_scores_tra)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (cross_scores_tra.mean(), cross_scores_tra.std()))\n",
    "print(\"CROSSSCORE test:\")\n",
    "print(cross_scores_test)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (cross_scores_test.mean(), cross_scores_test.std()))\n",
    "\n",
    "print(f\"How many coumns ins my_dataset? {len(my_dataset.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e044dc4",
   "metadata": {},
   "source": [
    "The warning above indicates indicates that one or more of the classes have very few instances. <br>\n",
    "This can potentially cause issues when performing cross-validation with a high number of splits. <br>\n",
    "One solution to address the problem can be to use Stratified cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb9c4473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/notto4/anaconda3/envs/MLearning/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/notto4/anaconda3/envs/MLearning/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROSSSCORE val:\n",
      "[1.         1.         0.66666667 1.         0.66666667]\n",
      "0.87 accuracy with a standard deviation of 0.16\n",
      "CROSSSCORE tra:\n",
      "[1.         1.         0.95833333 0.95833333 0.875     ]\n",
      "0.96 accuracy with a standard deviation of 0.05\n",
      "CROSSSCORE test:\n",
      "[1.         1.         0.66666667 0.66666667 1.        ]\n",
      "0.87 accuracy with a standard deviation of 0.16\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Stratified Sampling.\n",
    "To ensure that each fold of the cross-validation contains a proportional representation of each class\n",
    "\"\"\"\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Use stratified cross-validation\n",
    "cross_scores_tra = cross_val_score(clf, X_train, Y_train, cv=cv)\n",
    "cross_scores_test = cross_val_score(clf, X_test, Y_test, cv=cv)\n",
    "cross_scores_val = cross_val_score(clf, X_val, Y_val, cv=cv)\n",
    "\n",
    "print(\"CROSSSCORE val:\")\n",
    "print(cross_scores_val)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (cross_scores_val.mean(), cross_scores_val.std()))\n",
    "print(\"CROSSSCORE tra:\")\n",
    "print(cross_scores_tra)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (cross_scores_tra.mean(), cross_scores_tra.std()))\n",
    "print(\"CROSSSCORE test:\")\n",
    "print(cross_scores_test)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (cross_scores_test.mean(), cross_scores_test.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2e4d6b",
   "metadata": {},
   "source": [
    "ShuffleSplit (another Cross-Validation Strategy) to generates random subsets of data for each split. <br>\n",
    "Useful when dealing with imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1647ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROSSSCORE val:\n",
      "[0.66666667 1.         1.         0.66666667 1.        ]\n",
      "0.87 accuracy with a standard deviation of 0.16\n",
      "CROSSSCORE tra:\n",
      "[0.95833333 1.         1.         0.95833333 0.95833333]\n",
      "0.97 accuracy with a standard deviation of 0.02\n",
      "CROSSSCORE test:\n",
      "[1. 1. 1. 1. 1.]\n",
      "1.00 accuracy with a standard deviation of 0.00\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Reduce the splits to 3 \"\"\"\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "cross_scores_tra = cross_val_score(clf, X_train, Y_train, cv=cv)\n",
    "cross_scores_test = cross_val_score(clf, X_test, Y_test, cv=cv)\n",
    "cross_scores_val = cross_val_score(clf, X_val, Y_val, cv=cv)\n",
    "\n",
    "print(\"CROSSSCORE val:\")\n",
    "print(cross_scores_val)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (cross_scores_val.mean(), cross_scores_val.std()))\n",
    "print(\"CROSSSCORE tra:\")\n",
    "print(cross_scores_tra)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (cross_scores_tra.mean(), cross_scores_tra.std()))\n",
    "print(\"CROSSSCORE test:\")\n",
    "print(cross_scores_test)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (cross_scores_test.mean(), cross_scores_test.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8f8631f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Setosa       1.00      1.00      1.00         4\n",
      "  Versicolor       0.80      0.80      0.80         5\n",
      "   Virginica       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.88      0.88      0.88        15\n",
      "weighted avg       0.87      0.87      0.87        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "NB in case multi_target columns --> ValueError: multiclass-multioutput is not supported !\n",
    "The MultiOutputClassifier does not support multi-class multi-output classification. \n",
    "It is designed for multi-output regression problems, where each output is a continuous variable.\n",
    "\"\"\"\n",
    "yhat = clf.predict(X_test)\n",
    "cr_y1 = classification_report(Y_test,yhat)\n",
    "print(cr_y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3cfbbb",
   "metadata": {},
   "source": [
    "### => Other Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f63b3f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zer = zero_one_loss(Y_test, yhat,normalize=False)\n",
    "zer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2fb2b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7647058823529411"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jac = jaccard_score(Y_test, yhat, average=\"micro\")\n",
    "jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f19998f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13333333333333333"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamm = hamming_loss(Y_test, yhat)\n",
    "hamm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf74460c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [1.         0.8        0.83333333]\n",
      "recall: [1.         0.8        0.83333333]\n",
      "fscore: [1.         0.8        0.83333333]\n",
      "support: [4 5 6]\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore, support = scorep(Y_test, yhat)\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66e21eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preci = precision_score(Y_test.iloc[:, 0], yhat[:, 0], average='micro')\n",
    "preci = precision_score(Y_test, yhat, average='micro')\n",
    "preci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac86569",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "397fbc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SummaryWriter object to log data to TensorBoard\n",
    "log_dir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1923ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log each value separately with a unique tag\n",
    "for idx, score in enumerate(cross_scores_val):\n",
    "    tag = f\"CROSSSCORE val {idx}\"\n",
    "    writer.add_scalar(tag, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6275d775",
   "metadata": {},
   "outputs": [],
   "source": [
    "jac = jaccard_score(Y_test, yhat, average=\"micro\")\n",
    "zer = zero_one_loss(Y_test, yhat,normalize=False)\n",
    "hamm = hamming_loss(Y_test, yhat)\n",
    "\n",
    "writer.add_scalar('jaccard_score test', jac)\n",
    "writer.add_scalar('zero_one_loss test', zer)\n",
    "writer.add_scalar('hamming_loss test', hamm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a2df690",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, prec in enumerate(precision):\n",
    "    tag = f\"Precision {idx}\"\n",
    "    writer.add_scalar(tag, prec)\n",
    "\n",
    "for idx, reca in enumerate(recall):\n",
    "    tag = f\"Recall {idx}\"\n",
    "    writer.add_scalar(tag, reca)\n",
    "\n",
    "for idx, scor in enumerate(fscore):\n",
    "    tag = f\"F1score {idx}\"\n",
    "    writer.add_scalar(tag, scor)\n",
    "\n",
    "for idx, supp in enumerate(support):\n",
    "    tag = f\"Precision {idx}\"\n",
    "    writer.add_scalar(tag, supp)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e36eb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2dd19f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 70790), started 0:14:33 ago. (Use '!kill 70790' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d28697d71858cacf\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d28697d71858cacf\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
