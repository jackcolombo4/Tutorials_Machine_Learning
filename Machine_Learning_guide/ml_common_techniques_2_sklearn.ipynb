{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"line-height:1.2;\">\n",
    "\n",
    "<h1 style=\"color:#900C3F; margin-bottom: 0.2em;\">Common practices in Machine Learning 2</h1>\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"line-height:1.2;\">\n",
    "\n",
    "<h4 style=\"margin-top: 0.2em; margin-bottom: 0.5em;\">2 examples based on Scikit-learn. Focus on Tokenization and Identification. </h4>\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"margin-top: 5px;\">\n",
    "<span style=\"display: inline-block;\">\n",
    "    <h3 style=\"color: lightblue; display: inline; margin-bottom: 0;\">Keywords:</h3> SpaCy (for Natural Language Processing)\n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:#900C3F\"> Recap SpaCy: </h3>\n",
    "<div style=\"margin-top: -8px;\">\n",
    "Show the noun phrases and verbs in the text, as well as the named entities identified by Spacy, <br>\n",
    "such as persons, dates, and a cardinal number. <br>\n",
    "Load English tokenizer, tagger, parser and NER from \"en_core_web_sm\" model. <br>\n",
    "It contains pre-trained models for tokenization, part-of-speech tagging, parsing, and named entity recognition in English. <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping since SpaCy is already installed\n"
     ]
    }
   ],
   "source": [
    "%%script echo Skipping since SpaCy is already installed\n",
    "!pip install -U spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# To avoid printing warnings on CUDA initialization in TensorFlow when importing SpaCy:\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 0: default, 1: INFO, 2: WARNING, 3: ERROR\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained English language model from the spaCy library\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#900C3F\"> Example 1:</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\"\"\"Maya Angelou's writing career spanned over six decades, \n",
    "        during which she became known for her powerful poetry, \n",
    "        autobiographical works, and activism. Despite experiencing significant personal and professional obstacles, \n",
    "        including racism, poverty, and sexual assault, Angelou persevered and \n",
    "        created a body of work that has inspired and touched millions of readers around the world. \n",
    "        Her most famous work, \"I Know Why the Caged Bird Sings,\" is a memoir that recounts her childhood experiences \n",
    "        and has been praised for its honesty, vulnerability, and powerful message. \n",
    "        Angelou's writing has earned her numerous awards and accolades, and she remains one of the most influential writers of the 20th century.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Processing text: </font>\n",
    "<font size=\"4\"> \n",
    "- tokenizes the text <br>\n",
    "- assigns part-of-speech tags to each token <br>\n",
    "- performs dependency parsing to identify the syntactic relationships between tokens, <br>\n",
    "- identifies named entities in the text. <br>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Maya Angelou's writing career spanned over six decades, \n",
       "        during which she became known for her powerful poetry, \n",
       "        autobiographical works, and activism. Despite experiencing significant personal and professional obstacles, \n",
       "        including racism, poverty, and sexual assault, Angelou persevered and \n",
       "        created a body of work that has inspired and touched millions of readers around the world. \n",
       "        Her most famous work, \"I Know Why the Caged Bird Sings,\" is a memoir that recounts her childhood experiences \n",
       "        and has been praised for its honesty, vulnerability, and powerful message. \n",
       "        Angelou's writing has earned her numerous awards and accolades, and she remains one of the most influential writers of the 20th century."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Analyzing syntax: </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun phrases: [\"Maya Angelou's writing career\", 'over six decades', 'which', 'she', 'her powerful poetry', 'autobiographical works', 'activism', 'significant personal and professional obstacles', 'racism', 'poverty', 'sexual assault', 'Angelou', 'a body', 'work', 'that', 'millions', 'readers', 'the world', 'Her most famous work', 'I', 'Why the Caged Bird Sings', 'a memoir', 'that', 'her childhood experiences', 'its honesty', 'vulnerability', 'powerful message', \"Angelou's writing\", 'her', 'numerous awards', 'accolades', 'she', 'the most influential writers', 'the 20th century']\n"
     ]
    }
   ],
   "source": [
    "# Find contiguous spans of tokens that form noun phrases in the text.\n",
    "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbs: ['span', 'become', 'know', 'experience', 'include', 'persevere', 'create', 'inspire', 'touch', 'know', 'recount', 'praise', 'earn', 'remain']\n"
     ]
    }
   ],
   "source": [
    "# Show the lemmas of all the verbs, filtering for tokens with the part-of-speech tag \"VERB\" and the token.lemma_ attribute.\n",
    "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maya Angelou's PERSON\n",
      "six decades DATE\n",
      "Angelou PERSON\n",
      "millions CARDINAL\n",
      "Angelou PERSON\n",
      "the 20th century DATE\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Find and show named entities, phrases and concepts \"\"\"\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#900C3F\"> Example 2:</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Apple is looking at buying U.K. startup for $1 billion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "U.K. GPE\n",
      "$1 billion MONEY\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Print out the entities in the text.\n",
    "The doc.ents attribute identifies named entities in the text and assigns them entity labels, \n",
    "such as \"ORG\" for organizations and \"MONEY\" for monetary values.\n",
    "\"\"\"\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple PROPN nsubj\n",
      "is AUX aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.K. PROPN dobj\n",
      "startup NOUN dep\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "1 NUM compound\n",
      "billion NUM pobj\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tag and show the part-of-speech tags and dependencies for each token in the text\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "U.K.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Print out the noun chunks in the text. \n",
    "N.B.\n",
    "doc.noun_chunks\" finds contiguous spans of tokens that form noun phrases in the text.\n",
    "The part-of-speech tags and dependency labels provide information about the syntactic structure of the sentence, \n",
    "such as identifying the subject and object of a verb.\n",
    "\"\"\"\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
